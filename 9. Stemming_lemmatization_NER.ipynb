{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47669c36",
   "metadata": {
    "papermill": {
     "duration": 0.004884,
     "end_time": "2024-07-04T09:41:01.665725",
     "exception": false,
     "start_time": "2024-07-04T09:41:01.660841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> **Tokenization; Stop Word; Stemming; Lemitization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73026c68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:41:01.677930Z",
     "iopub.status.busy": "2024-07-04T09:41:01.677427Z",
     "iopub.status.idle": "2024-07-04T09:41:04.213571Z",
     "shell.execute_reply": "2024-07-04T09:41:04.212073Z"
    },
    "papermill": {
     "duration": 2.545812,
     "end_time": "2024-07-04T09:41:04.216739",
     "exception": false,
     "start_time": "2024-07-04T09:41:01.670927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sentence input used is : \n",
      "\n",
      " He stepped gingerly onto the bridge knowing, that enchantment awaited on the other side.\n",
      "It was difficult for Mary to admit; that most of her workout consisted of exercising poor judgment.\n",
      "\n",
      "\n",
      "The tokenized words are \n",
      " ['He', 'stepped', 'gingerly', 'onto', 'the', 'bridge', 'knowing', ',', 'that', 'enchantment', 'awaited', 'on', 'the', 'other', 'side', '.', 'It', 'was', 'difficult', 'for', 'Mary', 'to', 'admit', ';', 'that', 'most', 'of', 'her', 'workout', 'consisted', 'of', 'exercising', 'poor', 'judgment', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mayank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#1} Tokenization : Tokens are formed\n",
    "import nltk\n",
    "nltk.download(\"punkt\")#punkt sentence tokenizer tokenizes the sentence and works on unsupervised learning and can be trained on unlabled data.\n",
    "#   Word tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"He stepped gingerly onto the bridge knowing, that enchantment awaited on the other side.\\nIt was difficult for Mary to admit; that most of her workout consisted of exercising poor judgment.\"\n",
    "tokens = word_tokenize(text)\n",
    "print(\"\\nThe sentence input used is : \\n\\n\",text)\n",
    "print(\"\\n\\nThe tokenized words are \\n\",tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf56f3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:41:04.230719Z",
     "iopub.status.busy": "2024-07-04T09:41:04.230161Z",
     "iopub.status.idle": "2024-07-04T09:41:04.237744Z",
     "shell.execute_reply": "2024-07-04T09:41:04.236429Z"
    },
    "papermill": {
     "duration": 0.018389,
     "end_time": "2024-07-04T09:41:04.241059",
     "exception": false,
     "start_time": "2024-07-04T09:41:04.222670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The tokenized sentence are: \n",
      " ['He stepped gingerly onto the bridge knowing, that enchantment awaited on the other side.', 'It was difficult for Mary to admit; that most of her workout consisted of exercising poor judgment.']\n"
     ]
    }
   ],
   "source": [
    "#   Sentence tokenizer\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "tokens_sent = sent_tokenize(text)\n",
    "print(\"\\nThe tokenized sentence are: \\n\",tokens_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1a0d5bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:41:04.254833Z",
     "iopub.status.busy": "2024-07-04T09:41:04.254326Z",
     "iopub.status.idle": "2024-07-04T09:41:04.274890Z",
     "shell.execute_reply": "2024-07-04T09:41:04.273411Z"
    },
    "papermill": {
     "duration": 0.031029,
     "end_time": "2024-07-04T09:41:04.277972",
     "exception": false,
     "start_time": "2024-07-04T09:41:04.246943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'am', 'against', 'than', \"haven't\", 'your', 'herself', 'under', 'our', 'had', \"you've\", 'been', 'aren', 'between', 'hers', 'when', 'wouldn', 'too', 'theirs', 'weren', 'll', 'own', 'out', 'few', \"don't\", 'having', 't', 'mightn', 'shan', \"wouldn't\", 'doesn', \"hadn't\", 'just', 'ma', 'this', 'shouldn', 'wasn', 'any', 'with', 'she', 've', 'myself', 'but', 'were', \"you're\", 'have', 'by', 'yourself', 'himself', 'hasn', \"mustn't\", 'they', 'these', 'further', 'him', \"she's\", 'only', 'should', 'where', 'below', 'to', \"shan't\", 'now', 'm', 'i', 'don', 'ourselves', 'not', 'you', 'did', 'needn', 'above', 'same', 'won', 'me', 'o', 'his', 'can', 'as', 'haven', 'of', 'her', \"hasn't\", 'on', 'why', 'does', 'then', \"needn't\", 're', 'themselves', 'after', 'be', 'such', 'didn', 'other', 'during', 'is', 'because', 'if', 'so', 'through', 'do', 'over', \"didn't\", 'again', 'down', 'd', 'how', 'that', 'we', 'and', 'or', 'for', 'from', 'who', 'up', 'whom', \"couldn't\", 'are', 'a', 'isn', \"should've\", 'the', 'ours', 'being', 'them', 'some', 'here', 'at', 'there', \"shouldn't\", 'its', \"isn't\", 'he', 'their', \"won't\", \"you'd\", 'an', 'each', 'couldn', \"it's\", 'both', 'once', \"you'll\", \"that'll\", 'yours', 'before', 'what', \"weren't\", 'into', 'while', 'has', 'mustn', 'hadn', 'those', 'yourselves', 'nor', 'which', 'off', \"wasn't\", 'was', \"mightn't\", 'no', 'y', 'itself', 'until', 'will', 'all', 's', 'my', 'doing', 'most', \"doesn't\", 'in', \"aren't\", 'more', 'it', 'about', 'very', 'ain'}\n",
      "\n",
      "The stop words are removed now, Tokenized words or filtered tokenized words are : \n",
      "\n",
      " ['He', 'stepped', 'gingerly', 'onto', 'bridge', 'knowing', ',', 'enchantment', 'awaited', 'side', '.', 'It', 'difficult', 'Mary', 'admit', ';', 'workout', 'consisted', 'exercising', 'poor', 'judgment', '.']\n"
     ]
    }
   ],
   "source": [
    "#2} Stop Words : Common words which are often removed during nlp usage\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download(\"stop words\")\n",
    "\n",
    "stopwords= set(stopwords.words(\"english\"))\n",
    "print(stopwords)\n",
    "filtered_words = []\n",
    "\n",
    "for w in tokens:\n",
    "    if w not in stopwords:\n",
    "        filtered_words.append(w)\n",
    "print(\"\\nThe stop words are removed now, Tokenized words or filtered tokenized words are : \\n\\n\",filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b3da17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:41:04.293025Z",
     "iopub.status.busy": "2024-07-04T09:41:04.291989Z",
     "iopub.status.idle": "2024-07-04T09:41:04.300229Z",
     "shell.execute_reply": "2024-07-04T09:41:04.298835Z"
    },
    "papermill": {
     "duration": 0.019684,
     "end_time": "2024-07-04T09:41:04.303646",
     "exception": false,
     "start_time": "2024-07-04T09:41:04.283962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stemmed list items are: \t ['organ', 'organiz', 'factual', 'run']\n"
     ]
    }
   ],
   "source": [
    "#3} Stemming : Reduces the words to their root form or base form\n",
    "from nltk.stem import PorterStemmer\n",
    "words = [\"Organization\",\"Organizational\",\"Factual\",\"running\"]\n",
    "#    list item stemming\n",
    "stem_li = []\n",
    "ps = PorterStemmer()\n",
    "for i in words:\n",
    "    stem_li.append(ps.stem(i))\n",
    "\n",
    "print(\"The stemmed list items are: \\t\",stem_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "528aae2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:41:04.317845Z",
     "iopub.status.busy": "2024-07-04T09:41:04.317367Z",
     "iopub.status.idle": "2024-07-04T09:41:04.326616Z",
     "shell.execute_reply": "2024-07-04T09:41:04.325196Z"
    },
    "papermill": {
     "duration": 0.020141,
     "end_time": "2024-07-04T09:41:04.329688",
     "exception": false,
     "start_time": "2024-07-04T09:41:04.309547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'stepped', 'gingerly', 'onto', 'the', 'bridge', 'knowing', ',', 'that', 'enchantment', 'awaited', 'on', 'the', 'other', 'side', '.', 'It', 'was', 'difficult', 'for', 'Mary', 'to', 'admit', ';', 'that', 'most', 'of', 'her', 'workout', 'consisted', 'of', 'exercising', 'poor', 'judgment', '.']\n",
      "\n",
      "The stemmed list of tokenized words are : \t ['he', 'step', 'gingerli', 'onto', 'the', 'bridg', 'know', ',', 'that', 'enchant', 'await', 'on', 'the', 'other', 'side', '.', 'it', 'wa', 'difficult', 'for', 'mari', 'to', 'admit', ';', 'that', 'most', 'of', 'her', 'workout', 'consist', 'of', 'exercis', 'poor', 'judgment', '.']\n"
     ]
    }
   ],
   "source": [
    "#    Stemming for words on word tokens\n",
    "print(tokens)\n",
    "stem_words = []\n",
    "for i in tokens:\n",
    "    stem_words.append(ps.stem(i))\n",
    "    \n",
    "print(\"\\nThe stemmed list of tokenized words are : \\t\",stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b4ed6c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:41:04.344307Z",
     "iopub.status.busy": "2024-07-04T09:41:04.343766Z",
     "iopub.status.idle": "2024-07-04T09:41:04.351428Z",
     "shell.execute_reply": "2024-07-04T09:41:04.350197Z"
    },
    "papermill": {
     "duration": 0.018526,
     "end_time": "2024-07-04T09:41:04.354412",
     "exception": false,
     "start_time": "2024-07-04T09:41:04.335886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He stepped gingerly onto the bridge knowing, that enchantment awaited on the other side.', 'It was difficult for Mary to admit; that most of her workout consisted of exercising poor judgment.']\n",
      "The stemmed list of tokenized sentence are : \t ['he stepped gingerly onto the bridge knowing, that enchantment awaited on the other side.', 'it was difficult for mary to admit; that most of her workout consisted of exercising poor judgment.']\n"
     ]
    }
   ],
   "source": [
    "#    Stemming for senteces on sentenced tokens \n",
    "print(tokens_sent)\n",
    "stem_sentence = []\n",
    "for i in tokens_sent:\n",
    "    stem_sentence.append(ps.stem(i))\n",
    "    \n",
    "print(\"The stemmed list of tokenized sentence are : \\t\",stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5c7e402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:41:04.369043Z",
     "iopub.status.busy": "2024-07-04T09:41:04.368547Z",
     "iopub.status.idle": "2024-07-04T09:41:04.443866Z",
     "shell.execute_reply": "2024-07-04T09:41:04.442511Z"
    },
    "papermill": {
     "duration": 0.085961,
     "end_time": "2024-07-04T09:41:04.446662",
     "exception": false,
     "start_time": "2024-07-04T09:41:04.360701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mayank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4} Lemmatization : Breaks the words into simpler forms and makes meaning full words unlike stemming\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18f50026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:41:06.061816Z",
     "iopub.status.busy": "2024-07-04T09:41:06.061377Z",
     "iopub.status.idle": "2024-07-04T09:41:08.464012Z",
     "shell.execute_reply": "2024-07-04T09:41:08.462846Z"
    },
    "papermill": {
     "duration": 2.41415,
     "end_time": "2024-07-04T09:41:08.466824",
     "exception": false,
     "start_time": "2024-07-04T09:41:06.052674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lemmatized words of the list are : \t ['Organization', 'Organizational', 'Factual', 'running']\n"
     ]
    }
   ],
   "source": [
    "wl=WordNetLemmatizer()\n",
    "\n",
    "#   list item lemmitization\n",
    "lemma_li=[]\n",
    "for i in words: \n",
    "    lemma_li.append(wl.lemmatize(i))\n",
    "    \n",
    "print(\"The lemmatized words of the list are : \\t\",lemma_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa1ad411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:41:08.482354Z",
     "iopub.status.busy": "2024-07-04T09:41:08.481931Z",
     "iopub.status.idle": "2024-07-04T09:41:08.489297Z",
     "shell.execute_reply": "2024-07-04T09:41:08.487946Z"
    },
    "papermill": {
     "duration": 0.018124,
     "end_time": "2024-07-04T09:41:08.491808",
     "exception": false,
     "start_time": "2024-07-04T09:41:08.473684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lemmatized words of the sentence words tokens will be : \n",
      " ['He', 'stepped', 'gingerly', 'onto', 'the', 'bridge', 'knowing', ',', 'that', 'enchantment', 'awaited', 'on', 'the', 'other', 'side', '.', 'It', 'wa', 'difficult', 'for', 'Mary', 'to', 'admit', ';', 'that', 'most', 'of', 'her', 'workout', 'consisted', 'of', 'exercising', 'poor', 'judgment', '.']\n"
     ]
    }
   ],
   "source": [
    "lemma_words = []\n",
    "for i in tokens:\n",
    "    lemma_words.append(wl.lemmatize(i))\n",
    "    \n",
    "print(\"The lemmatized words of the sentence words tokens will be : \\n\",lemma_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d2aadcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T09:41:08.507832Z",
     "iopub.status.busy": "2024-07-04T09:41:08.507454Z",
     "iopub.status.idle": "2024-07-04T09:41:08.514164Z",
     "shell.execute_reply": "2024-07-04T09:41:08.512751Z"
    },
    "papermill": {
     "duration": 0.018372,
     "end_time": "2024-07-04T09:41:08.517426",
     "exception": false,
     "start_time": "2024-07-04T09:41:08.499054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lemmatized sentence will be of the paragraph is : \n",
      " ['He stepped gingerly onto the bridge knowing, that enchantment awaited on the other side.', 'It was difficult for Mary to admit; that most of her workout consisted of exercising poor judgment.']\n"
     ]
    }
   ],
   "source": [
    "lemma_sentence = []\n",
    "for i in tokens_sent:\n",
    "    lemma_sentence.append(wl.lemmatize(i))\n",
    "    \n",
    "print(\"The lemmatized sentence will be of the paragraph is : \\n\",lemma_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39a2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.068842,
   "end_time": "2024-07-04T09:41:09.447224",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-04T09:40:57.378382",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
